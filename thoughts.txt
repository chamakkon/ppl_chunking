以下に、あなたがこれまで組み上げてきた **「NSEベースのViterbiチャンク分割アルゴリズム」** を、
**そのまま実装に渡せる完全な技術仕様書**としてまとめます。

---

# =========================================================

# **文チャンク分割アルゴリズム 技術仕様書**

# **（NSE × DP × Viterbi）**

# =========================================================

## 1. **目的**

入力されたテキストを文単位に分割し、
**文単体の自然さ（ノードコスト）** と
**チャンク間の接続自然さ（接続コスト）** を用いて、
最も自然で情報構造を保った **最適チャンク列** を動的計画法（DP）により求める。

本方式は

* Normalized Sentence Entropy（NSE: 0–1 のスコア）
* DP / Viterbi アルゴリズム
  を組み合わせた**確率的チャンク分割**手法である。

---

# 2. **定義と前提**

テキストを文分割し、文列を以下とする：

[
S = {S_1, S_2, \dots, S_N}
]

チャンク (C) は連続する文の区間で定義：

[
C = S_{s..t} = {S_s, S_{s+1}, \dots, S_t}
]

チャンク列は：

[
{C_1, C_2, \dots, C_K} \quad (C_0 = \text{BOS})
]

---

# 3. **スコアリングモデル**

## 3.1 **ノードスコア（チャンク単体の自然さ）**

チャンク (C) を単独で LM に入力し、
Normalized Sentence Entropy（0〜1）を計算する：

[
P_{\text{node}}(C) = \text{NSE}(C \mid \text{none})
]

DP で扱いやすいように log に変換：

[
\phi(C) = \log P_{\text{node}}(C)
]

---

## 3.2 **接続スコア（チャンク間の自然な流れ）**

直前チャンク (C_{i-1}) をコンテキストとして (C_i) の NSE を計算：

[
P_{\text{trans}}(C_i \mid C_{i-1}) = \text{NSE}(C_i \mid C_{i-1})
]

同様に log：

[
\psi(C_i \mid C_{i-1}) = \log P_{\text{trans}}(C_i \mid C_{i-1})
]

**BOS**（開始チャンク）については：

[
\psi(C_1 \mid C_0) = 0
]

---

## 3.3 **1チャンクあたりの総合スコア**

本仕様では
**ノードコストと接続コストの重み λ を 1 に固定する。**

[
F(C_i, C_{i-1})
= \phi(C_i) + \psi(C_i \mid C_{i-1})
]

---

## 3.4 **パス全体のスコア（平均化済み）**

パス長 (K) のチャンク列全体のスコア：

[
\text{PathScore}
= \frac{1}{K} \sum_{i=1}^K F(C_i, C_{i-1})
]

平均化する理由：

* チャンク数の違いによる「乗数の呪い」を排除
* チャンク数の多寡に依存しない公平な比較が可能

---

# 4. **動的計画法（DP / Viterbi）**

## 4.1 **DP テーブル**

* `DP_score[j]`
  　文 1〜j を最適にチャンクしたときの**総 log スコア**

* `DP_chunks[j]`
  　そのときのチャンク数

* `prev[j]`
  　文 j のチャンク開始位置（復元用）

---

## 4.2 **初期化**

```
DP_score[0] = 0
DP_chunks[0] = 0
prev[0] = -1
```

---

## 4.3 **遷移式**

文 j を終端とするチャンク候補を
すべての s（1 ≤ s ≤ j）に対して評価する。

チャンク：

[
C = S_{s..j}
]

ノードスコア：

[
\phi(C)
]

接続スコア：

* s = 1 → 0
* s > 1 →
  [
  \psi(C \mid C_{\text{prev}})
  = \log \text{NSE}(C \mid C_{\text{prev}})
  ]

遷移：

```
score = DP_score[s-1] + φ(C) + ψ(C | C_prev)
chunks = DP_chunks[s-1] + 1
```

最大スコアを与える s を選択：

```
DP_score[j] = score
DP_chunks[j] = chunks
prev[j] = s
```

---

## 4.4 **解の復元**

```
chunks = []
j = N
while j > 0:
    s = prev[j]
    chunks.append((s, j))
    j = s - 1

chunks.reverse()
```

これにより最適チャンク列が得られる。

---

# 5. **最終スコアの算出**

アルゴリズムの最終評価値は：

[
\text{FinalScore} =
\frac{DP_score[N]}{DP_chunks[N]}
]

これは「1チャンクあたり平均 log スコア」。

---

# 6. **制約・実装オプション（任意）**

以下は必要に応じて追加する：

* チャンク最小文数：`L_min`
* チャンク最大文数：`L_max`
* 最大探索幅（window 制限）
  　`j - W_max ≤ s ≤ j`
* トークン数制約
  　`tokens(S_s..S_j) ≤ token_max`
* Punctuation-based pruning
  　句読点や embed slope から境界候補を絞る

---

# 7. **NSE 計算方法（実装者向け）**

### ● ノード NSE

[
\text{NSE}(C \mid \text{none})
= 1 - \frac{H(C \mid \text{none})}{H_{\max}}
]

### ● 接続 NSE

[
\text{NSE}(C \mid C_{\text{prev}})
= 1 - \frac{H(C \mid C_{\text{prev}})}{H_{\max}}
]

（H → 文の平均クロスエントロピー,
H_max → 正規化定数）

※ 正規化方式は使用するLMに応じて調整可。

---

# 8. **アルゴリズム全体フロー（まとめ）**

1. 文分割する
2. 全チャンク候補に対して

   * NSE(C | none) と log を計算
3. 全文ペア (C_prev, C) について

   * NSE(C | C_prev) と log を計算
4. DP にて最適な境界 s を毎ステップ選択
5. prev[] を辿って最適チャンク列を復元
6. 最後に平均 log スコアを算出

---

# 9. **本仕様の特徴**

* 文自体の自然さと文脈自然さを同等比重で評価（λ=1）
* ロバストで過剰分割されにくい
* Viterbi による全体最適化
* log + 平均化で「乗数の呪い」を回避
* RAG 向けのチャンク生成として安定

---

# =========================================================

# **以上、本チャンク分割アルゴリズムの正式仕様書。**

# =========================================================

必要なら、
**疑似コード版**
**実装用テンプレ（Python / PyTorch / NumPy）**
**計算量削減版（windowed Viterbi）**
なども追加できます。
